# Attention is all you need

[![article](https://img.shields.io/badge/article-link-green?style=flat&logo=article)](https://tad-ai.github.io/1_transformers.html)
[![medium](https://img.shields.io/badge/medium-gray?style=flat&logo=medium)]()

Welcome to the "Attention is All You Need" repository!

This repository contains the implementation of the paper "Attention is All You Need" by Ashish Vaswani et al. The paper presents a new architecture called the Transformer, which is based solely on the self-attention mechanism to compute representations of input sequences.

In this repository, you will find the original paper along with its implementation in NumPy and PyTorch separately. Please note that the NumPy implementation is provided for educational purposes only and is not optimized for performance. For further advancements, we recommend using the PyTorch implementation.

We hope this repository is helpful in understanding and experimenting with the Transformer architecture. If you have any questions or feedback, please feel free to reach out to us.